---
title: "Análise de Séries Temporais - Trabalho 2"
author: "Davi Guerra Alves - Henrique Oliveira Dumay"
date: '2023-07-02'
output: pdf_document
header-includes:
 \usepackage{float}
---


```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
lapply(c('dplyr','lubridate','Mcomp','forecast','tseries','ggplot2','ggpubr','stringr'),require,character.only=TRUE)
# Dados
data(M3)
id <- 1686
serie = M3[[id]]$x
```


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.pos = 'H')
```

# Apresentação

A série analisada consiste na série número `r id` pertencente ao banco de dados da competição de previsão M3, disponível no pacote *Mcomp* do software R. A série descreve o número de carregamentos com código _TD-AUTOUNITS_, mensalmente, de outubro de 1984 a setembro de 1993. 

```{r, fig.align="center",fig.cap='Comportamento da série ao longo do tempo',echo=FALSE}
M3[[id]] %>% plot(xlab="Ano", ylab="n.º de carregamentos")
```

# Decomposição MSTL

```{r,fig.align="center",fig.cap='Decomposição MSTL', echo = FALSE}
mstl(serie, s.window= c(12)) %>% 
  plot(main="Série Original")
```
A decomposição MSTL mostra os componentes de tendência, sazonalidade e erro da série estudada. Percebe-se a presença de uma tendência crescente, com múltiplas sazonalidades que apesentam mudança do comportamento ao longo do tempo. É possível observar, graficamente, um alargamento da sazonalidade ao fim da série quando comparando ao início da série. 

# Modelos ARIMA

A presença do componente de tendência explicita a não-estacionaridade da série original.A função ndiffs() é utilizada para estimar o número de diferenças exigidas para tornar a série estacionária por meio de um teste de raíz unitária, com a hipótese nula de que a série tem raízes estacionárias contra a hipótese alternativa de que a série tem raíz unitária. O teste retorna o menor número de diferenças exigidas para o teste em um nível de significância de 95%. Já a função nsdiffs() utiliza testes de raíz unitária para determinar o número de diferenças sazonais para tornar a série estacionária. 

Com o uso das funções acima, obteve-se o valor para $d = 1$ e $D = 0$. Os modelos candidatos terão a forma:

$$SARIMA(p, 1, q) \times (P, 0, Q)_{12}$$

```{r, echo = FALSE, include = FALSE, echo = FALSE}
serie %>%
  ndiffs()             # d = 1

serie %>%
  diff() %>%
  nsdiffs()            # D = 0

serie_dif <- serie %>% 
  diff() 
```

A estacionariedade da série pode ser testada utilizando o teste Kwiatkowski-Phillips-Schmidt-Shin (KPSS), com a hipótese nula de que a série é estacionária. O teste resulta em um valor de `r kpss.test(serie_dif)[[1]]`, com p-valor de `r kpss.test(serie_dif)[[3]]`, que não nos permite rejeitar a hipótese nula a um nível de significância $\alpha = 0,05$.

```{r, include = FALSE}
kpss.test(serie_dif)
```
Consideramos que a série é, agora, estacionária, observamos os gráficos da função de autocorrelação (ACF) e da função de autocorrelação parcial (PACF) em busca de possíveis autocorrelações entre os diferentes atrasos da série. Os gráficos a seguir ilustram a série diferenciada, assim como os gráficos das funções de ACF e PACF.

```{r, fig.align="center",fig.cap='Gráficos ACF e PACF', echo = FALSE}

par(mfrow=c(3,1),mar=c(4, 3, 3, 1) + 0.5)
plot(serie_dif,main="Série diferenciada")
acf(serie_dif, lag = 5*12, main="ACF") 
pacf(serie_dif, lag = 5*12, main="PACF")
```
Dos gráficos apresentados, pode-se afirmar que a série diferenciada não apresenta um padrão claro de autocorrelações simples e sazonais que permita inferir diretamente a modelagem. Neste sentido, serão testados valores diferentes para *p*, *P*, *q* e *Q* e os diferentes modelos serão comparados por meio do critério AIC.

Para os diferentes valores de $(p,q,P,Q)$ teremos:

```{r, echo = FALSE}
melhor_AICc = Inf
for (P in 0:1) { 
  for (Q in 0:1) {
    for (p in 0:3) { 
      for (q in 0:3) {
        fit = Arima(serie, order=c(p,1,q), seasonal=c(P,0,Q))
        if (fit$aicc < melhor_AICc) { 
          melhor_AICc = fit$aicc
          cat("p =",p,", q =",q,", P =",P,", Q =",Q,", AICc =", fit$aicc, "\n")
        }
      }
    }
  }
}
```
O modelo com menor AICc foi o $SARIMA(1,1,1) \times (1,0,1)_{12}$. 

Os coeficientes do modelo proposto, portanto, serão obtidos do cálculo da função Arima com o modelo acima proposto. Os coeficientes do modelo terão a seguinte forma:

```{r, include = FALSE}
fit_arima <- Arima(serie, order=c(1,1,1), seasonal=c(1,0,1))
fit_arima
```


$$\phi_1 = 0,3152; \theta_1 = -0,9218; \varphi = 0,9606; \vartheta = -0,7359$$
Utilizaremos o modelo ARIMA acima definido com a transformação de Box-Cox com o objetivo de estabilizar os diferentes tipos de variação ao longo do tempo. O novo modelo tem os seguintes coeficientes:

```{r, include = FALSE}
fit_arima_boxcox = Arima(serie,order=c(1,1,1),seasonal=c(1,0,1), lambda = 'auto')
fit_arima_boxcox
```
$$\phi_1 = 0,2756; \theta_1 = -0,9209; \varphi = 0,9994; \vartheta = -0,9653$$

## Análise de Resíduos

Os resíduos do modelo ARIMA sem transformação apresentam o seguinte comportamentos gráficos:

```{r fig.align="center",fig.cap='Resíduos ARIMA sem transformação', echo = FALSE}
par(mfrow=c(2,2))
plot(fit_arima$residuals, ylab = "Resíduos", xlab = "")
acf(fit_arima$residuals, main="")
pacf(fit_arima$residuals, main="")
qqnorm(fit_arima$residuals, main="")
qqline(fit_arima$residuals)
```
Já os resíduos do modelo ARIMA com transformação Box-Cox apresentam o seguinte comportamentos gráficos:

```{r fig.align="center",fig.cap='Resíduos ARIMA com transformação boxcox', echo = FALSE}
par(mfrow=c(2,2))
plot(fit_arima_boxcox$residuals, ylab = "Resíduos", xlab = "")
acf(fit_arima_boxcox$residuals, main="")
pacf(fit_arima_boxcox$residuals, main="")
qqnorm(fit_arima_boxcox$residuals, main="")
qqline(fit_arima_boxcox$residuals)
```

Graficamente, observa-se que os resíduos de ambos os modelos parecem distribuir-se simetricamente ao retor da origem e não apresentam autocorrelações bem definidas. Precisa-se, entretanto, testá-los para estacionariedade, independência e distribuição normal. Essas hipóteses serão testadas conforme se segue.

A estacionaridade será testada a partir do teste Kwiatkowski-Phillips-Schmidt-Shin (KPSS), com a hipótese nula de que a série é estacionária. O teste para o modelo $SARIMA(1,1,1) \times (1,0,1)_{12}$ e para o mesmo modelo, utilizando a transformação de Box-Cox:

| Modelo | KPSS | P-valor |
|:---:|:---:|:---:|
| SARIMA sem Box-Cox | `r kpss.test(fit_arima$residuals)[[1]]` | `r kpss.test(fit_arima$residuals)[[3]]` |
| SARIMA com Box-Cox | `r kpss.test(fit_arima_boxcox$residuals)[[1]]` | `r kpss.test(fit_arima_boxcox$residuals)[[3]]` |

De acordo com o teste KPSS, não se pode rejeitar a hipótese de estacionariedade dos resíduos de ambos os modelos. 

O teste de independência dos resíduos é realizado a partir do teste Ljung-Box, com a hipótese $H_0$ de que os resíduos são idenpendentemente distribuídos. O teste apresenta os seguintes valores para os dois modelos:

| Modelo | Chi-Quadrado | Graus de liberdade | P-valor |
|:---:|:---:|:---:|:---:|
| SARIMA sem Box-Cox | `r Box.test(fit_arima$residuals, lag = 15, type ="Ljung-Box")[[1]]` | `r Box.test(fit_arima$residuals, lag = 15, type ="Ljung-Box")[[2]]` | `r Box.test(fit_arima$residuals, lag = 15, type ="Ljung-Box")[[3]]` |
| SARIMA com Box-Cox | `r Box.test(fit_arima_boxcox$residuals, lag = 15, type ="Ljung-Box")[[1]]` | `r Box.test(fit_arima_boxcox$residuals, lag = 15, type ="Ljung-Box")[[2]]` | `r Box.test(fit_arima_boxcox$residuals, lag = 15, type ="Ljung-Box")[[3]]` |

```{r, include = FALSE}
Box.test(fit_arima$residuals, lag = 15, type ="Ljung-Box")[[3]]
```
Os resultados acima mostram que a independência dos resíduos pode ser rejeitada ao nível de significância de 5% no modelo que utiliza a transformação de Box-Cox, enquanto não pode ser rejeitada no modelo SARIMA natural. 

A normalidade dos resíduos é testada com o teste Shapiro-Wilk de Normalidade, com $H_0$ de que os resíduos apresentam distribuição normal. O valor do teste estatístico para os dois modelos trabalhados é:

| Modelo | W | P-valor |
|:---:|:---:|:---:|
| SARIMA sem Box-Cox | `r shapiro.test(fit_arima$residuals)[[1]]` | `r shapiro.test(fit_arima$residuals)[[2]]` |
| SARIMA com Box-Cox | `r shapiro.test(fit_arima_boxcox$residuals)[[1]]` | `r shapiro.test(fit_arima_boxcox$residuals)[[2]]` |

Do resultado acima, não se pode rejeitar a hipótese de normalidade dos resíduos de ambos os modelos. 

```{r, include = FALSE}
shapiro.test(fit_arima$residuals)[[2]]
```


## Previsões

As previsões dos modelos:

```{r, fig.align="center", fig.cap="Previsões dos modelos ARIMA", echo = FALSE}
arima_layout <- layout(matrix(c(1,2),ncol=1), heights=c(20,20), TRUE)
fit_arima %>% forecast(h=24, level=c(80, 95)) %>% plot(xlab = "Arima(1,1,1)x(1,0,1)[12]", main = "")
fit_arima_boxcox %>% forecast(h=24, level=c(80, 95)) %>% plot(xlab = "Arima(1,1,1)x(1,0,1)[12] com Box-Cox", main = "")
```


# Modelos ETS

O modelo ETS (Error, trend and seasonal) permite descrever os modelos de alisamento exponencial em função dos tipos de suas componentes: tendência, sazonalidade e erro. O modelo utiliza três caracteres como identificação de acordo com a terminologia adotada por Hyndman et al. (2002) e Hyndman et al. (2008). A primeira letra se refere ao componente do erro; a segunda, ao componente da tendência e a terceira, da sazonalidade. A série anteriormente descrita apresenta tendência e sazonalidade claras à decomposição realizada e, portanto, trabalharemos com componentes de modelagem que contenham essas características. 

Os modelos que apresentam as características observadas na decomposição e seus respectivos AICcs estão representados na tabela abaixo:

| Modelo | AICc |
|---|:---:|
| AAA | 1950.568 |
| AAA Dumped | 1953.429 |
| MAA | 1947.757 |
| MAA Dumped | 1942.956 |
| MAM | 1925.053 |
| MAM Dumped | 1928.537 |
| MMM | 1923.268 |
| MMM Dumped | 1928.128 |

O modelo com menor AICc e, portanto, o modelo com melhor desempenho comparativo é o "MMM", em que apresenta componentes multiplicativos para previsões de erros, tendência e sazonalidade. 

```{r, include = FALSE}
componentes_tendencia = c("A","M")
componentes_sazonais = c("A","M")
componentes_erros = c("A","M")

model_ets = function(y,model,damped){
  tryCatch({
    ets(y,model,damped)
  },
  error=function(cond)print('nao pode')
  )
}

damped = F
melhor_AICc = Inf   
melhor_modelo = ""
for(comp_erro in componentes_erros){
  for(comp_tend in componentes_tendencia){
    for(comp_saz in componentes_sazonais){
      for(damped in c(T,F)){
        modelo = paste0(comp_erro,comp_tend,comp_saz)
        print("------------")
        print(modelo)
        print("damped=")
        print(damped)
        modelo_ets = model_ets(serie, model=modelo, damped = damped)
        print(modelo_ets['aicc'])
      }
    }
  }
}
fit_ets <- ets(serie, model = "MMM", damped = FALSE)
```
O modelo selecionado apresenta a seguinte estrutura:

$$
\begin{aligned}
\mu_t &= l_{t-1} b_{t-1}s_{t-m}\\
l_t &= l_{t-1}b_{t-1}+\frac{\alpha \epsilon_t}{s_{t-m}}\\
b_t &=b_{t-1}+\frac{\beta \epsilon_t}{s_{t-m}l_{t-1}} \\
s_t &=s_{t-m} + \frac{\gamma \epsilon_t}{l_{t-1}b_{t-1}}
\end{aligned}
$$

```{r, fig.align="center", fig.cap="Decomposição ETS", echo = FALSE}
plot(fit_ets, xlab = "Decomposição ETS")
```

## Resíduos

Os resíduos do modelo ETS selecionado são ilustrados na figura a seguir:

```{r, fig.align="center", fig.cap="Análise de Resíduos", echo = FALSE}
E <- fit_ets$residuals
par(mfrow=c(2,2)); 
plot(E, xlab = "Tempo", ylab = "");
acf(E, main="");
pacf(E, main="");
qqnorm(E, main="");qqline(E)
```

Observa-se que os resíduos parecem comportar-se de maneira aleatória, com distribuição normal e sem autocorrelações importantes entre diferentes lags. Os testes formais encontram-se na tabela abaixo, a exemplo do anteriormente realizado:

```{r, include = FALSE}
kpss.test(E)
Box.test(E, lag = 15, type ="Ljung-Box")
shapiro.test(E)

```

| Teste | Valor do teste | P-valor |
|---|---|:---:|
| KPSS | 0.12301 | 0.1 |
| Box-Ljung | 25.522 | 0.04336 |
| Shapiro-Wilk | 0.98751 | 0.4163 |

Os resultados acima apresentados sugerem que os resíduos do modelo são estacionários, apresentam distribuição normal, entretanto, é possível a rejeição da hipótese nula de independência.

Uma previsão do modelo para 12 novos períodos é ilustrada abaixo:

```{r, , fig.align="center", fig.cap="Previsão ETS", echo = FALSE}
fit_ets %>% forecast(h=12) %>% plot(main="Previsão ETS 'MMM'")
```



```{r}
#passo 1) aplicar cada um dos modelos ets na série
fit_ses = ets(serie, model = "ANN", damped=FALSE)
fit_holt = ets(serie, model = "AAN", damped=FALSE)
fit_holt_damped = ets(serie, model = "AAN", damped=TRUE)
fit_holt_aditivo = ets(serie, model = "AAA", damped=FALSE)
fit_holt_multi = ets(serie, model = "MAM", damped=FALSE)
```


```{r}
#passo 2) selecionar o melhor modelo aicc

fit_ses$aicc
fit_holt$aicc
fit_holt_damped$aicc
fit_holt_aditivo$aicc
fit_holt_multi$aicc

#menor aicc foi do modelo  Holt Winter Multiplicativo, com o valor de 1925.053
```


```{r}
#passo 3) verifique as suposições da série
residuos_holt_multi <- fit_holt_multi$residuals %>% window(start=1985)

par(mfrow=c(2,2))
plot(residuos_holt_multi)
acf(residuos_holt_multi)
pacf(residuos_holt_multi)
qqnorm(residuos_holt_multi)
qqline(residuos_holt_multi)

#estacionariedade
kpss.test(residuos_holt_multi)

#independencia
Box.test(residuos_holt_multi, lag = 15, type ="Ljung-Box")

#normalidade
shapiro.test(residuos_holt_multi)

#a série é normal, independente e estacionária.
```


```{r}
#passo 4) Calcule previsões pontuais utilizando o modelo selecionado;
fit_holt_multi %>% forecast(h=12) %>% plot()
```


```{r}
# passo 4) Obtenha previsões intervalares utilizando o modelo de espaço de estado equivalente
```



